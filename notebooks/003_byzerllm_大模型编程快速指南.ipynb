{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: byzerllm in /Users/allwefantasy/projects/byzer-llm/src (0.1.100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x108038100>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/byzerllm/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x108038400>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/byzerllm/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x1080385b0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/byzerllm/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x108038760>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/byzerllm/\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=75420): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x108038910>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/byzerllm/\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:09:17,446\tINFO usage_lib.py:472 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "2024-06-14 11:09:17,446\tINFO scripts.py:764 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m127.0.0.1\u001b[22m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0mTraceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/byzerllm/bin/ray\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/scripts/scripts.py\", line 2612, in main\n",
      "    return cli()\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/click/core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/autoscaler/_private/cli_logger.py\", line 856, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/scripts/scripts.py\", line 791, in start\n",
      "    node = ray._private.node.Node(\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/_private/node.py\", line 333, in __init__\n",
      "    self.start_head_processes()\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/_private/node.py\", line 1352, in start_head_processes\n",
      "    self._write_cluster_info_to_kv()\n",
      "  File \"/opt/miniconda3/envs/byzerllm/lib/python3.10/site-packages/ray/_private/node.py\", line 1307, in _write_cluster_info_to_kv\n",
      "    assert curr_val == self._session_name.encode(\"utf-8\"), (\n",
      "AssertionError: Session name session_2024-06-14_11-09-17_450726_75566 does not match persisted value b'session_2024-06-05_10-52-07_488244_8234'. Perhaps there was an error connecting to Redis.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -U byzerllm\n",
    "ray start --head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "byzerllm deploy --pretrained_model_type saas/openai \\\n",
    "--cpus_per_worker 0.001 \\\n",
    "--gpus_per_worker 0 \\\n",
    "--worker_concurrency 10 \\\n",
    "--num_workers 1 \\\n",
    "--infer_params saas.base_url=\"https://api.deepseek.com/v1\" saas.api_key=${MODEL_DEEPSEEK_TOKEN} saas.model=deepseek-chat \\\n",
    "--model deepseek_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-14 15:06:16.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbyzerllm.utils.connect_ray\u001b[0m:\u001b[36mconnect_cluster\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mJDK 21 will be used (/Users/allwefantasy/.auto-coder/jdk-21.0.2.jdk/Contents/Home)...\u001b[0m\n",
      "2024-06-14 15:06:16,893\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-06-14 15:06:16,919\tINFO worker.py:1740 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好！我是一个人工智能助手，旨在提供信息查询、建议和解答问题等服务。如果你有任何问题或需要帮助，请随时告诉我。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import byzerllm\n",
    "\n",
    "llm = byzerllm.ByzerLLM.from_default_model(model=\"deepseek_chat\")\n",
    "\n",
    "@byzerllm.prompt(llm = llm )\n",
    "def hello(q:str) ->str:\n",
    "    '''\n",
    "    你好, {{ q }}\n",
    "    '''\n",
    "\n",
    "hello(\"你是谁\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n你好, 你是谁'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello.prompt(\"你是谁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好！我是一个人工智能助手，专门设计来回答问题、提供信息和帮助解决问题。如果你有任何疑问或需要帮助，请随时告诉我。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello.with_llm(llm).run(\"你是谁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-14 14:42:04.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbyzerllm.utils.connect_ray\u001b[0m:\u001b[36mconnect_cluster\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mJDK 21 will be used (/Users/allwefantasy/.auto-coder/jdk-21.0.2.jdk/Contents/Home)...\u001b[0m\n",
      "2024-06-14 14:42:04,411\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-06-14 14:42:04,415\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "从前，森林里住着一只聪明的小狐狸。一天，它发现了一块闪闪发光的宝石。小狐狸决定用这块宝石帮助森林里的动物们。它用宝石的光芒指引迷路的小鹿找到了回家的路，用宝石的温暖治愈了受伤的小鸟。从此，小狐狸成了森林里的英雄，动物们都感激它的善良和智慧。\n"
     ]
    }
   ],
   "source": [
    "import byzerllm\n",
    "from byzerllm import ByzerLLM\n",
    "\n",
    "llm = ByzerLLM.from_default_model(\"deepseek_chat\")\n",
    "\n",
    "@byzerllm.prompt()\n",
    "def tell_story() -> str:\n",
    "    \"\"\"\n",
    "    讲一个100字的故事。    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "s = (\n",
    "    tell_story.with_llm(llm)\n",
    "    .with_response_markers()\n",
    "    .options({\"llm_config\": {\"max_length\": 10}})\n",
    "    .run()\n",
    ")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "勇敢的小鸟\n"
     ]
    }
   ],
   "source": [
    "import pydantic \n",
    "\n",
    "class Story(pydantic.BaseModel):\n",
    "    '''\n",
    "    故事\n",
    "    '''\n",
    "\n",
    "    title: str = pydantic.Field(description=\"故事的标题\")\n",
    "    body: str = pydantic.Field(description=\"故事主体\")\n",
    "\n",
    "@byzerllm.prompt()\n",
    "def tell_story()->Story:\n",
    "    '''\n",
    "    讲一个100字的故事。    \n",
    "    '''\n",
    "\n",
    "s = tell_story.with_llm(llm).run()\n",
    "print(isinstance(s, Story))\n",
    "print(s.title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from loguru import logger\n",
    "import re\n",
    "\n",
    "@byzerllm.prompt()\n",
    "def generate_regex_pattern(desc: str) -> str:\n",
    "    \"\"\"\n",
    "    根据下面的描述生成一个正则表达式，要符合python re.compile 库的要求。\n",
    "\n",
    "    {{ desc }}\n",
    "\n",
    "    最后生成的正则表达式要在<REGEX></REGEX>标签对里。\n",
    "    \"\"\"    \n",
    "\n",
    "def extract_regex_pattern(regex_block: str) -> str:    \n",
    "    pattern = re.search(r\"<REGEX>(.*)</REGEX>\", regex_block, re.DOTALL)\n",
    "    if pattern is None:\n",
    "        logger.warning(\"No regex pattern found in the generated block:\\n {regex_block}\")\n",
    "        raise None\n",
    "    return pattern.group(1)\n",
    "\n",
    "pattern = \"匹配一个邮箱地址\"\n",
    "v = generate_regex_pattern.with_llm(llm).with_extractor(extract_regex_pattern).run(desc=pattern)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jane Doe,\n",
      "\n",
      "I hope this message finds you well. I wanted to remind you of your 3 pending tasks to ensure you stay on track:\n",
      "\n",
      "1. **Submit report** - This task is due on **2024-03-10**. Please ensure that you allocate time to complete and submit the report before the deadline.\n",
      "\n",
      "2. **Finish project** - The deadline for this project is **2024-03-15**. It's important to keep an eye on your progress and make adjustments as necessary to meet this due date.\n",
      "\n",
      "3. **Reply to emails** - This task is due soonest, on **2024-03-08**. Responding to emails promptly is crucial for maintaining good communication and relationships.\n",
      "\n",
      "Please prioritize these tasks according to their urgency and importance. If you need any assistance or have any questions, feel free to reach out.\n",
      "\n",
      "Best regards,\n",
      "Your Reminder System\n"
     ]
    }
   ],
   "source": [
    "import byzerllm\n",
    "data = {\n",
    "    'name': 'Jane Doe',\n",
    "    'task_count': 3,\n",
    "    'tasks': [\n",
    "        {'name': 'Submit report', 'due_date': '2024-03-10'},\n",
    "        {'name': 'Finish project', 'due_date': '2024-03-15'},\n",
    "        {'name': 'Reply to emails', 'due_date': '2024-03-08'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "class RAG():\n",
    "    def __init__(self):        \n",
    "        self.llm = byzerllm.ByzerLLM()\n",
    "        self.llm.setup_template(model=\"deepseek_chat\",template=\"auto\")\n",
    "        self.llm.setup_default_model_name(\"deepseek_chat\")        \n",
    "    \n",
    "    @byzerllm.prompt(lambda self:self.llm)\n",
    "    def generate_answer(self,name,task_count,tasks)->str:\n",
    "        '''\n",
    "        Hello {{ name }},\n",
    "\n",
    "        This is a reminder that you have {{ task_count }} pending tasks:\n",
    "        {% for task in tasks %}\n",
    "        - Task: {{ task.name }} | Due: {{ task.due_date }}\n",
    "        {% endfor %}\n",
    "\n",
    "        Best regards,\n",
    "        Your Reminder System\n",
    "        '''        \n",
    "\n",
    "t = RAG()\n",
    "\n",
    "response = t.generate_answer(**data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-14 14:59:25.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbyzerllm.utils.connect_ray\u001b[0m:\u001b[36mconnect_cluster\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mJDK 21 will be used (/Users/allwefantasy/.auto-coder/jdk-21.0.2.jdk/Contents/Home)...\u001b[0m\n",
      "2024-06-14 14:59:25,508\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-06-14 14:59:25,509\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Jane Doe,\n",
      "\n",
      "Just a gentle nudge to keep you on track with your pending tasks. Here's a quick recap:\n",
      "\n",
      "1. **Submit report** - Your deadline is approaching on **2024-03-10**. Ensure all data is accurate and the report is comprehensive before submission.\n",
      "\n",
      "2. **Finish project** - Aim to wrap up your project by **2024-03-15**. Double-check all components and ensure they meet the project's objectives.\n",
      "\n",
      "3. **Reply to emails** - Time-sensitive responses are needed by **2024-03-08**. Prioritize urgent emails and maintain clear communication.\n",
      "\n",
      "Remember, staying ahead of these deadlines will help maintain your productivity and efficiency. If you need any assistance or have questions, feel free to reach out.\n",
      "\n",
      "Best regards,\n",
      "Your Reminder System\n"
     ]
    }
   ],
   "source": [
    "import byzerllm\n",
    "\n",
    "data = {\n",
    "    'name': 'Jane Doe',\n",
    "    'task_count': 3,\n",
    "    'tasks': [\n",
    "        {'name': 'Submit report', 'due_date': '2024-03-10'},\n",
    "        {'name': 'Finish project', 'due_date': '2024-03-15'},\n",
    "        {'name': 'Reply to emails', 'due_date': '2024-03-08'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "class RAG():\n",
    "    def __init__(self):        \n",
    "        self.llm = byzerllm.ByzerLLM.from_default_model(model=\"deepseek_chat\")\n",
    "    \n",
    "    @byzerllm.prompt()\n",
    "    def generate_answer(self,name,task_count,tasks)->str:\n",
    "        '''\n",
    "        Hello {{ name }},\n",
    "\n",
    "        This is a reminder that you have {{ task_count }} pending tasks:\n",
    "            \n",
    "        {{ tasks }}\n",
    "\n",
    "        Best regards,\n",
    "        Your Reminder System\n",
    "        '''\n",
    "        \n",
    "        tasks_str = \"\\n\".join([f\"- Task: {task['name']} | Due: { task['due_date'] }\" for task in tasks])\n",
    "        return {\"tasks\": tasks_str}\n",
    "\n",
    "t = RAG()\n",
    "\n",
    "response = t.generate_answer.with_llm(t.llm).run(**data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time(time='2024-06-14')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydantic\n",
    "class Time(pydantic.BaseModel):\n",
    "    time: str = pydantic.Field(...,description=\"时间，时间格式为 yyyy-MM-dd\")\n",
    "\n",
    "\n",
    "@llm.impl()\n",
    "def calculate_current_time()->Time:\n",
    "    '''\n",
    "    计算当前时间\n",
    "    '''\n",
    "    pass \n",
    "\n",
    "\n",
    "calculate_current_time()\n",
    "#output: Time(time='2024-06-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-14 15:12:21.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbyzerllm.utils.connect_ray\u001b[0m:\u001b[36mconnect_cluster\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mJDK 21 will be used (/Users/allwefantasy/.auto-coder/jdk-21.0.2.jdk/Contents/Home)...\u001b[0m\n",
      "2024-06-14 15:12:21,271\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-06-14 15:12:21,272\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你好\n",
      "！\n",
      "我\n",
      "是一个\n",
      "人工智能\n",
      "助手\n",
      "，\n",
      "旨在\n",
      "提供\n",
      "信息\n",
      "、\n",
      "解答\n",
      "问题\n",
      "和\n",
      "帮助\n",
      "用户\n",
      "解决问题\n",
      "。\n",
      "如果你\n",
      "有\n",
      "任何\n",
      "疑问\n",
      "或\n",
      "需要\n",
      "帮助\n",
      "，\n",
      "请\n",
      "随时\n",
      "告诉我\n",
      "。\n"
     ]
    }
   ],
   "source": [
    "import byzerllm\n",
    "\n",
    "llm = byzerllm.ByzerLLM.from_default_model(model=\"deepseek_chat\")\n",
    "\n",
    "v = llm.stream_chat_oai(model=\"deepseek_chat\",conversations=[{\n",
    "    \"role\":\"user\",\n",
    "    \"content\":\"你好，你是谁\",\n",
    "}],delta_mode=True)\n",
    "\n",
    "for t in v:\n",
    "    print(t[0],flush=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-14 15:14:33.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mbyzerllm.utils.connect_ray\u001b[0m:\u001b[36mconnect_cluster\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mJDK 21 will be used (/Users/allwefantasy/.auto-coder/jdk-21.0.2.jdk/Contents/Home)...\u001b[0m\n",
      "2024-06-14 15:14:33,546\tINFO worker.py:1564 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2024-06-14 15:14:33,547\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一个人工智能助手，旨在提供信息、解答问题和帮助用户解决问题。如果你有任何问题或需要帮助，请随时告诉我。\n"
     ]
    }
   ],
   "source": [
    "import byzerllm\n",
    "\n",
    "llm = byzerllm.ByzerLLM.from_default_model(model=\"deepseek_chat\")\n",
    "\n",
    "v = llm.chat_oai(model=\"deepseek_chat\",conversations=[{\n",
    "    \"role\":\"user\",\n",
    "    \"content\":\"你好，你是谁\",\n",
    "}])\n",
    "\n",
    "print(v[0].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List,Dict,Any,Annotated\n",
    "import pydantic \n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def compute_date_range(count:Annotated[int,\"时间跨度，数值类型\"],\n",
    "                       unit:Annotated[str,\"时间单位，字符串类型\",{\"enum\":[\"day\",\"week\",\"month\",\"year\"]}])->List[str]:\n",
    "    '''\n",
    "    计算日期范围\n",
    "\n",
    "    Args:\n",
    "        count: 时间跨度，数值类型\n",
    "        unit: 时间单位，字符串类型，可选值为 day,week,month,year\n",
    "    '''        \n",
    "    now = datetime.datetime.now()\n",
    "    now_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    if unit == \"day\":\n",
    "        return [(now - relativedelta(days=count)).strftime(\"%Y-%m-%d %H:%M:%S\"),now_str]\n",
    "    elif unit == \"week\":\n",
    "        return [(now - relativedelta(weeks=count)).strftime(\"%Y-%m-%d %H:%M:%S\"),now_str]\n",
    "    elif unit == \"month\":\n",
    "        return [(now - relativedelta(months=count)).strftime(\"%Y-%m-%d %H:%M:%S\"),now_str]\n",
    "    elif unit == \"year\":\n",
    "        return [(now - relativedelta(years=count)).strftime(\"%Y-%m-%d %H:%M:%S\"),now_str]\n",
    "    return [\"\",\"\"]\n",
    "\n",
    "def compute_now()->str:\n",
    "    '''\n",
    "    计算当前时间\n",
    "    '''\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-06-14 15:18:02']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = llm.chat_oai([{\n",
    "    \"content\":'''计算当前时间''',\n",
    "    \"role\":\"user\"    \n",
    "}],tools=[compute_date_range,compute_now],execute_tool=True)\n",
    "\n",
    "t[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2024-03-14 15:19:13', '2024-06-14 15:19:13']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = llm.chat_oai([{\n",
    "    \"content\":'''最近三个月趋势''',\n",
    "    \"role\":\"user\"    \n",
    "}],tools=[compute_date_range,compute_now],execute_tool=True)\n",
    "\n",
    "t[0].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byzerllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
