{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Prompt Functions with Deepseek Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import byzerllm\n",
    "\n",
    "# Initialize the ByzerLLM with deepseek model\n",
    "llm = byzerllm.ByzerLLM.from_default_model(model=\"deepseek_chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@byzerllm.prompt(llm=llm)\n",
    "def hello(q: str) -> str:\n",
    "    '''\n",
    "    你好, {{ q }}\n",
    "    '''\n",
    "\n",
    "response = hello(\"你是谁\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt rendering\n",
    "rendered_prompt = hello.prompt(\"你是谁\")\n",
    "print(\"Rendered prompt:\", rendered_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@byzerllm.prompt()\n",
    "def tell_story() -> str:\n",
    "    \"\"\"\n",
    "    讲一个100字的故事。    \n",
    "    \"\"\"\n",
    "\n",
    "story = (\n",
    "    tell_story.with_llm(llm)\n",
    "    .with_response_markers()\n",
    "    .options({\"llm_config\": {\"max_length\": 10}})\n",
    "    .run()\n",
    ")\n",
    "print(story)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}